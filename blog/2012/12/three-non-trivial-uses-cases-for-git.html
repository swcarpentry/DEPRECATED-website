{% extends "_blog.html" %}
{% block file_metadata %}
<meta name="journal" content="True" />
<meta name="post_id" content="5370" />
<meta name="author_id" content="limare.n" />
<meta name="title" content="Three Non-trivial Use Cases for Git" />
<meta name="post_date" content="2012-12-15" />
<meta name="category" content="community" />
{% endblock file_metadata %}
{% block content %}

<p><em>Today's guest post comes from <a href="http://nicolas.limare.net/">Nicolas Limare</a>.</em></p>

<p>Here are three problems I encountered while introducing fellow grad students and post-docs to Git. These are situations where Git seems to not provide a the solution we need, either because it requires the addition of an external service provider, unusual configuration steps not adapted to beginners, or simply because the functionality is missing in Git. Or maybe did I just ignore the perfect command or option which would have answered all my wishes?</p>

<p><strong>1. Simple Collaboration</strong></p>

<p>Two or three people want to work together on a single repository, like they are used to with svn. No branch, no pull request, no GitHub magic, just one shared bare repo on the lab server, cloned and sync'd onto everyone's own laptop via SSH. The problem is to allow proper read/write permissions for everyone. Basic UNIX groups are not practical, for example because they require to go through the local sysadmin for every new project, and to define a new group per project. In that case, my solution is to use POSIX extended ACLs:</p>

<pre>
setfacl -Rm u:USER:rwX '~/code/project.git'
setfacl -Rm d:u:USER:rwX '~/code/project.git'
</pre>

<p>It is fairly clean, standard, and works perfectly, but these ACLs are usually not enabled by default on filesystems and sysadmins may not want to allow them. Moreover, non-admin users are not used to work with this kind of permissions and having to touch them to collaborate feels abnormal.</p>

<p><strong>2. Sharing Binary Data</strong></p>

<p>I had a group of students working on a shared dataset. One person would produce the input data, and other persons would process them, in chain, each with their own program. Everything is in a Git repo, everyone's program is stored in source code and built with makefile, the data is processed in chain with makefile too, and so far everything is fine. But the input data is regularly updated, and it's a hundred 10Mpixel JPEG images. So the size of the repository quickly becomes quite heavy (JPEG is already compressed, and doesn't shrink any further in Git, and binary diff of JPEG is, or was, inefficient).</p>

<p>This huge weight is the problem. We want to keep the history ans to be able to go back to previous versions of the data, but we absolutely don't want every one in the group to have on their own machine 25 different versions of a 100MB dataset. The solution may be git-annex, but it didn't exist at this time. It's certainly also possible with git rebase and squash every time the input data is updated, but this git-fu is too too complex for our simple needs. I ant people to be able to configure their local repo so that it behaves only keeps less than a configurable amount of data locally, something like a permanent shallow clone.</p>

<p><strong>3. Mirroring</strong></p>

<p>I was also trying to sell Git as a good solution to replicate files between two machines, either for website or web app deployment, or to maintain a workspace in different places. A sort of improved rsync, with the Git history magic.</p>

<p>But to do that with Git, pushing updates from one machines to another, the receiving Git needs to automatically perform a checkout. This step requires some hook configuration (by itself non-trivial for beginners), and the checkout must be very carefully configured to be performed at the right place, and to behave correctly when some files need to be deleted or local changes overwritten. This is too esoteric for a simple need.</p>
{% endblock content %}
